import re
import time
import logging
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class TradeSignal:
    symbol: str
    direction: str
    entry_prices: List[float]
    limit_prices: List[float]
    take_profits: List[float]
    stop_loss: Optional[float]
    leverage: Optional[int]
    margin: Optional[float]
    source: str
    timestamp: float
    is_market: bool = False


class UniversalSignalParser:
    def __init__(self):
        self.patterns = {
            "direction": {
                "long": ["long", "–ª–æ–Ω–≥", "buy", "–∫—É–ø–∏—Ç—å", "–≤–≤–µ—Ä—Ö", "—Ä–æ—Å—Ç"],
                "short": ["short", "—à–æ—Ä—Ç", "sell", "–ø—Ä–æ–¥–∞—Ç—å", "–≤–Ω–∏–∑", "–ø–∞–¥–µ–Ω–∏–µ"]
            },
            "entry": [
                "–≤—Ö–æ–¥", "entry", "—Ç–≤—Ö", "—Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞", "–≤—Ö–æ–¥–∏–º", "–≤—Ö–æ–¥:",
                "entry:", "–≤—Ö–æ–¥–Ω–∞—è", "–≤—Ö–æ–¥ –ø–æ", "—Ü–µ–Ω–∞ –≤—Ö–æ–¥–∞", "take entry"
            ],
            "take_profit": [
                "—Ç–µ–π–∫", "–ø—Ä–æ—Ñ–∏—Ç", "—Ü–µ–ª—å", "target", "tp", "—Ü–µ–ª–∏:",
                "take profit", "—Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç", "–ø–æ —Ü–µ–ª—è–º", "–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω—ã–µ —Ü–µ–ª–∏",
                "—Ñ–∏–∫—Å–∞—Ü–∏—è", "—Ñ–∏–∫—Å–∏—Ä—É–µ–º", "—Ü–µ–ª–∏", "targets", "—Ü–µ–ª–∏ :", "—Ç–µ–π–∫–∏:",
                "—Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç -", "—Ç–æ—á–∫–∏ —Ñ–∏–∫—Å–∞—Ü–∏–∏", "—Ñ–∏–∫—Å–∞—Ü–∏–∏"
            ],
            "stop_loss": [
                "—Å—Ç–æ–ø", "—Å—Ç–æ–ø-–ª–æ—Å—Å", "stop", "sl", "stop loss", "–ª–æ—Å—Å",
                "—Å—Ç–æ–ø –ª–æ—Å—Å", "—Å—Ç–æ–ø:", "stop:", "—Å—Ç–æ–ø :", "—Å—Ç–æ–ø-–ª–æ—Å—Å:", "—Å—Ç–æ–ø :", "—Å—Ç–æ–ø-–ª–æ—Å—Å -"
            ],
            "market": ["—Ä—ã–Ω–æ–∫", "market", "–ø–æ —Ä—ã–Ω–∫—É", "–º–∞—Ä–∫–µ—Ç", "market entry", "MARKET"],
            "limit": ["–ª–∏–º–∏—Ç", "limit", "–ª–∏–º–∏—Ç–∫–∞", "–ª–∏–º–∏—Ç–Ω—ã–π", "–ª–∏–º–∏—Ç–Ω—ã–π –æ—Ä–¥–µ—Ä", "–ª–∏–º–∏—Ç–Ω—ã–π –æ—Ä–¥–µ—Ä –Ω–∞"],
            "leverage": ["–ø–ª–µ—á–æ", "leverage", "x", "–∫—Ä–∞—Ç–Ω–æ—Å—Ç—å", "leverage:", "–ø–ª–µ—á–æ:", "–ª–∏–≤–µ—Ä–∏–¥–∂"],
            "margin": ["–º–∞—Ä–∂–∞", "margin", "–¥–µ–ø–æ–∑–∏—Ç", "–¥–µ–ø–æ", "—Ä–∏—Å–∫", "–æ–±—ä–µ–º", "% –æ—Ç", "–Ω–∞ %"],
            "average": ["—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ", "–¥–æ–±–æ—Ä", "average", "–¥–æ–±–∞–≤–∏—Ç—å", "add"],
            "separators": {
                "range": ["-", "‚Äî", "–¥–æ", "–ø–æ", "–∏–ª–∏", "–∏"],
                "list": [",", ";", "|", "/", "–∏", "–∏–ª–∏", ":", "‚Äî", "-"],
                "decimal": [".", ","]
            }
        }

        self.stop_words = {
            'LONG', 'SHORT', 'USDT', 'BTC', 'ETH', 'TP', 'SL',
            'ENTRY', 'STOP', 'LOSS', 'TAKE', 'PROFIT', 'TARGET',
            'X', '–í–•–û–î', '–í–´–•–û–î', '–°–¢–û–ü', '–¶–ï–õ–¨', '–î–û–ë–û–†',
            'NESTEROV', 'FAMILY', 'TWO', 'FINGERS', 'PRIVATE',
            'CLUB', 'CRYPTO', 'FUTURES', 'COINFY', 'CRYPTOGRAD',
            'SHEF', 'FINANSIST', '–ó–ê–ö–†–´–¢–û–ï', '–°–û–û–ë–©–ï–°–¢–í–û', '–®–ê–§–ò–ù–ê–ù–°–ò–°–¢'
        }

    def normalize_text(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if not text:
            return ""

        # –£–¥–∞–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Markdown
        patterns = [
            (r'\*\*(.*?)\*\*', r'\1'),  # **text**
            (r'\*(.*?)\*', r'\1'),  # *text*
            (r'__(.*?)__', r'\1'),  # __text__
            (r'_(.*?)_', r'\1'),  # _text_
            (r'`(.*?)`', r'\1'),  # `code`
            (r'~~(.*?)~~', r'\1'),  # ~~text~~
        ]

        normalized = text
        for pattern, replacement in patterns:
            normalized = re.sub(pattern, replacement, normalized)

        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ –≤ –¥–µ—Å—è—Ç–∏—á–Ω—ã—Ö —á–∏—Å–ª–∞—Ö
        def replace_comma(match):
            num = match.group(0)
            if ',' in num:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —á–∏—Å–ª–æ —Å –¥–µ—Å—è—Ç–∏—á–Ω–æ–π –∑–∞–ø—è—Ç–æ–π
                parts = num.split(',')
                if len(parts) == 2 and parts[1].replace(' ', '').isdigit():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —á–∞—Å—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                    if '-' not in num and '‚Äî' not in num:
                        return parts[0] + '.' + parts[1]
            return num

        normalized = re.sub(r'\d+,\d+', replace_comma, normalized)

        # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –º–µ—à–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥—É
        special_chars = '~$‚Ç¨‚ÇΩ‚Ä¢‚Üí‚ûú‚ñ∂‚ñº‚ñ≤‚óè‚óã‚óÜ‚óá‚ñ†‚ñ°‚ñ¢‚ñ£‚ñ§‚ñ•‚ñ¶‚ñß‚ñ®‚ñ©‚ñ™‚ñ´‚ñ¨‚ñ≠‚ñÆ‚ñØ‚òê‚òë‚òí‚úÖ‚úì‚úî‚úï‚úñ‚úó‚úò‚ùå‚ùé'
        for char in special_chars:
            normalized = normalized.replace(char, ' ')

        # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        normalized = re.sub(r'\s+', ' ', normalized).strip()

        return normalized

    def detect_source(self, text: str, channel_name: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ —Å–∏–≥–Ω–∞–ª–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ"""
        if not text:
            return channel_name.upper()

        lines = [line.strip() for line in text.strip().split('\n') if line.strip()]

        if not lines:
            return channel_name.upper()

        text_lower = text.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –≤ —Ç–µ–∫—Å—Ç–µ
        sources = {
            "NESTEROV": ["nesterov", "family", "–Ω–µ—Å—Ç–µ—Ä–æ–≤"],
            "CRYPTOGRAD": ["cryptograd", "–∫—Ä–∏–ø—Ç–æ–≥—Ä–∞–¥"],
            "PRIVATE_CLUB": ["private", "club", "–ø—Ä–∞–π–≤–∞—Ç", "–∫–ª—É–±", "–ø—Ä–∞–π–≤–∞—Ç –∫–ª–∞–±"],
            "CRYPTOFUTURES": ["cryptofutures", "–∫—Ä–∏–ø—Ç–æ—Ñ—å—é—á–µ—Ä—Å"],
            "COINFY": ["coinfy", "–∫–æ–∏–Ω—Ñ–∏"],
            "TWO_FINGERS": ["two fingers", "—Ç—É —Ñ–∏–Ω–≥–µ—Ä—Å"],
            "SHEF_FINANSIST": ["—à–µ—Ñ —Ñ–∏–Ω–∞–Ω—Å–∏—Å—Ç", "shef finansist"]
        }

        for source_name, keywords in sources.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return source_name

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ CryptoGrad
        has_cryptograd_format = (
                re.search(r'—Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞:.*?–ª–∏–º–∏—Ç–Ω—ã–π –æ—Ä–¥–µ—Ä', text_lower) or
                re.search(r'–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω—ã–µ —Ü–µ–ª–∏:', text_lower) or
                re.search(r'–º–∞—Ä–∂–∞: –∫—Ä–æ—Å—Å', text_lower)
        )

        if has_cryptograd_format:
            return "CRYPTOGRAD"

        # –ò—â–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫–∞—Ö
        for i, line in enumerate(lines[:3]):
            line_lower = line.lower()
            line_upper = line.upper()

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è —Å–∏–º–≤–æ–ª–æ–º
            is_symbol_line = (
                    line.startswith('#') or
                    line.startswith('$') or
                    line.startswith('üé§') or
                    re.search(r'/USDT', line_upper) or
                    re.search(r'\b(?:LONG|SHORT)\b', line_upper) or
                    len(line.split()) <= 2
            )

            if not is_symbol_line:
                # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É –æ—Ç —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
                clean_line = re.sub(r'[^\w\s]', '', line).strip()
                if clean_line and len(clean_line) > 2:
                    if not re.search(r'\d', clean_line) and not re.search(r'[^\w\s]', clean_line):
                        first_word = clean_line.split()[0]
                        if len(first_word) > 2:
                            return first_word.upper()

        return channel_name.upper()

    def extract_symbol(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∏–º–≤–æ–ª –∏–∑ —Ç–µ–∫—Å—Ç–∞ - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥"""
        if not text:
            return "UNKNOWN"

        lines = text.split('\n')

        for line in lines:
            line_upper = line.upper().strip()

            # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            clean_line = re.sub(r'[^\w\s/#$]', '', line_upper).strip()

            # 1. #SYMBOL –∏–ª–∏ #SYMBOLUSDT
            match = re.search(r'#([A-Z0-9]{2,10})(?:USDT)?\b', clean_line)
            if match:
                symbol = match.group(1)
                if symbol not in self.stop_words:
                    return self.normalize_symbol(symbol)

            # 2. $SYMBOL (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è Two Fingers: ‚úÖ$ Zec)
            match = re.search(r'\$([A-Z0-9]{2,10})\b', clean_line)
            if match:
                symbol = match.group(1)
                if symbol not in self.stop_words:
                    return self.normalize_symbol(symbol)

            # 3. SYMBOL/USDT (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –®–µ—Ñ –§–∏–Ω–∞–Ω—Å–∏—Å—Ç: üé§BCH/USDT)
            match = re.search(r'\b([A-Z0-9]{2,10})/USDT\b', clean_line)
            if match:
                return self.normalize_symbol(match.group(1))

            # 4. SYMBOL USDT
            match = re.search(r'\b([A-Z0-9]{2,10})\s+USDT\b', clean_line)
            if match:
                return self.normalize_symbol(match.group(1))

            # 5. SYMBOL LONG/SHORT
            match = re.search(r'\b([A-Z0-9]{2,10})\s+(?:LONG|SHORT)\b', clean_line)
            if match:
                symbol = match.group(1)
                if (symbol not in self.stop_words and
                        not re.match(r'\d+[A-Z]+', symbol)):
                    return self.normalize_symbol(symbol)

            # 6. LONG/SHORT SYMBOL
            match = re.search(r'\b(?:LONG|SHORT)\s+([A-Z0-9]{2,10})\b', clean_line)
            if match:
                symbol = match.group(1)
                if symbol not in self.stop_words:
                    return self.normalize_symbol(symbol)

            # 7. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è 1000PEPE - —Ç–µ–ø–µ—Ä—å –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ PEPE
            if re.search(r'1000PEPE', clean_line):
                return "PEPEUSDT"

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —è–≤–Ω–æ, –∏—â–µ–º –ª—é–±—É—é –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—É
        for line in lines:
            clean_line = re.sub(r'[^\w\s]', '', line.upper())
            words = re.findall(r'\b[A-Z0-9]{2,8}\b', clean_line)
            for word in words:
                if (word not in self.stop_words and
                        not word.isdigit() and
                        len(word) >= 2 and
                        not re.fullmatch(r'\d+[X–•]', word)):
                    if re.match(r'\d+[A-Z]+', word):
                        match_letters = re.search(r'[A-Z]+', word)
                        if match_letters:
                            return self.normalize_symbol(match_letters.group(0))
                        continue
                    return self.normalize_symbol(word)

        return "UNKNOWN"

    def normalize_symbol(self, symbol: str) -> str:
        """–ü—Ä–∏–≤–æ–¥–∏—Ç —Å–∏–º–≤–æ–ª –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É"""
        if not symbol:
            return "UNKNOWN"

        symbol = symbol.replace('/', '').replace('#', '').replace('$', '').upper()

        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π USDT
        if symbol.endswith('USDT'):
            symbol = symbol[:-4]

        # –î–æ–±–∞–≤–ª—è–µ–º USDT –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if not symbol.endswith('USDT'):
            symbol = symbol + 'USDT'

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥–≤–æ–π–Ω–æ–π USDT (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
        if symbol.endswith('USDTUSDT'):
            symbol = symbol[:-4]

        return symbol

    def extract_direction(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–¥–µ–ª–∫–∏"""
        if not text:
            return "UNKNOWN"

        text_upper = text.upper()
        text_lower = text.lower()

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if re.search(r'\bLONG\b', text_upper):
            return "LONG"
        if re.search(r'\bSHORT\b', text_upper):
            return "SHORT"

        # –ó–∞—Ç–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in self.patterns["direction"]["long"]:
            if re.search(r'\b' + re.escape(keyword) + r'\b', text_lower):
                return "LONG"

        for keyword in self.patterns["direction"]["short"]:
            if re.search(r'\b' + re.escape(keyword) + r'\b', text_lower):
                return "SHORT"

        return "UNKNOWN"

    def extract_leverage(self, text: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–ª–µ—á–æ"""
        if not text:
            return 1

        text_upper = text.upper()

        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ 50X, 20x
        patterns = [
            r'(\d+)[X–•]\b',
            r'\b(\d+)\s*[X–•]\b',
            r'–ü–õ–ï–ß–û[^\d]*(\d+)',
            r'LEVERAGE[^\d]*(\d+)',
            r'\b(\d+)X\s*LEVERAGE',
        ]

        for pattern in patterns:
            match = re.search(pattern, text_upper)
            if match:
                try:
                    leverage = int(match.group(1))
                    if 1 <= leverage <= 100:
                        return leverage
                except (ValueError, IndexError):
                    continue

        # –î–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 10-50x) -> –±–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ
        range_match = re.search(r'(\d+)\s*[-‚Äî]\s*(\d+)\s*[X–•]', text_upper)
        if range_match:
            try:
                leverage1 = int(range_match.group(1))
                leverage2 = int(range_match.group(2))
                avg_leverage = (leverage1 + leverage2) // 2
                if 1 <= avg_leverage <= 100:
                    return avg_leverage
            except (ValueError, IndexError):
                pass

        return 1

    def extract_margin(self, text: str) -> Optional[float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞—Ä–∂—É (% –æ—Ç –¥–µ–ø–æ–∑–∏—Ç–∞)"""
        if not text:
            return None

        text_lower = text.lower()

        patterns = [
            r'(\d+(?:[.,]\d+)?)%\s*–æ—Ç\s*(?:—Ç–æ—Ä–≥–æ–≤–æ–≥–æ\s*)?–¥–µ–ø–æ–∑–∏—Ç–∞',
            r'–Ω–∞\s*(\d+(?:[.,]\d+)?)%\s*–æ—Ç\s*–¥–µ–ø–æ',
            r'–º–∞—Ä–∂–∞\s*(\d+(?:[.,]\d+)?)%',
            r'—Ä–∏—Å–∫\s*(\d+(?:[.,]\d+)?)%',
            r'(\d+(?:[.,]\d+)?)%\s*–¥–µ–ø–æ',
            r'(\d+(?:[.,]\d+)?)%\s*–æ–±—ä–µ–º',
            r'(\d+(?:[.,]\d+)?)%\s*–≤\s*—Å–¥–µ–ª–∫—É',
            r'–∑–∞—Ö–æ–¥–∏–º\s*–º–∞–∫—Å–∏–º—É–º\s*–Ω–∞\s*(\d+(?:[.,]\d+)?)%',
        ]

        for pattern in patterns:
            match = re.search(pattern, text_lower)
            if match:
                try:
                    margin = float(match.group(1).replace(',', '.'))
                    if 0.1 <= margin <= 100:
                        return margin
                except (ValueError, IndexError):
                    continue

        return None

    def find_prices_by_context(self, text: str, context_keywords: List[str]) -> List[float]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ü–µ–Ω—ã –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        if not text:
            return []

        prices = []
        lines = text.split('\n')

        for i, line in enumerate(lines):
            line_lower = line.lower()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ —Å—Ç—Ä–æ–∫–µ
            normalized_line = re.sub(r'[^\w\s:]', '', line_lower)

            has_context = any(keyword in normalized_line for keyword in context_keywords)

            if has_context:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—ã –∏–∑ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏
                line_prices = self.extract_prices_from_line(line, filter_percents=True)
                prices.extend(line_prices)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ (–¥–ª—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤)
                j = i + 1
                while j < len(lines) and j < i + 10:
                    next_line = lines[j].strip()
                    if not next_line:
                        j += 1
                        continue

                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Ü–∏—Ñ—Ä—ã –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ü–µ–Ω—ã
                    if (re.match(r'^\d+[.,]\d+', next_line) or
                            len(self.extract_prices_from_line(next_line, filter_percents=True)) > 0 and
                            len(re.findall(r'[–∞-—è–ê-–Øa-zA-Z]', next_line)) < 3):
                        next_prices = self.extract_prices_from_line(next_line, filter_percents=True)
                        prices.extend(next_prices)
                        j += 1
                    else:
                        break

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        seen = set()
        unique_prices = []
        for price in prices:
            if price not in seen:
                seen.add(price)
                unique_prices.append(price)

        return unique_prices

    def extract_prices_from_line(self, line: str, filter_percents: bool = False) -> List[float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Ü–µ–Ω—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
        if not line:
            return []

        prices = []

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–ø—è—Ç—ã–µ –≤ —Ç–æ—á–∫–∞—Ö
        normalized_line = line.replace(',', '.')

        # –£–¥–∞–ª—è–µ–º –∑–Ω–∞–∫–∏ –≤–∞–ª—é—Ç –∏ –¥—Ä—É–≥–∏–µ –º–µ—à–∞—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã
        normalized_line = re.sub(r'[$‚Ç¨‚ÇΩ:~]', '', normalized_line)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∑–Ω–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
        has_percent_sign = '%' in line

        # –ò—â–µ–º —á–∏—Å–ª–∞ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π –∏ —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞
        matches = re.findall(r'\b\d+\.\d+\b|\b\d+\b', normalized_line)

        for match in matches:
            try:
                price = float(match)

                # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã
                if not (0.000001 <= price <= 1000000):
                    continue

                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
                if filter_percents and has_percent_sign:
                    # –ò—â–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∏—Å—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
                    percent_pattern = rf'{re.escape(match)}\s*%'
                    if re.search(percent_pattern, line):
                        continue

                prices.append(price)
            except ValueError:
                continue

        return prices

    def extract_entry_info(self, text: str, source: str) -> Tuple[List[float], List[float], bool]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ö–æ–¥–µ (—Ü–µ–Ω—ã, —Ç–∏–ø)"""
        if not text:
            return [], [], False

        text_lower = text.lower()

        entry_prices = []
        limit_prices = []
        is_market = False

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —è–≤–Ω—ã–µ —É–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ä—ã–Ω–æ—á–Ω—ã–π –≤—Ö–æ–¥
        market_keywords = self.patterns["market"] + ["–ø–æ —Ä—ã–Ω–∫—É", "market", "MARKET"]
        for keyword in market_keywords:
            if keyword in text_lower:
                is_market = True
                logger.info(f"üîç Found market keyword: {keyword}")
                break

        # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –≤—Ö–æ–¥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5.370-5.360)
        direction = self.extract_direction(text)

        for line in text.split('\n'):
            range_match = re.search(r'(\d+[.,]\d+)\s*[-‚Äî]\s*(\d+[.,]\d+)', line)
            if range_match:
                try:
                    price1 = float(range_match.group(1).replace(',', '.'))
                    price2 = float(range_match.group(2).replace(',', '.'))

                    line_lower = line.lower()
                    if any(keyword in line_lower for keyword in self.patterns["entry"]):
                        # –≠—Ç–æ –¥–∏–∞–ø–∞–∑–æ–Ω –≤—Ö–æ–¥–∞
                        # –î–ª—è SHORT —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é, –¥–ª—è LONG –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é
                        if direction == "SHORT":
                            entry_prices = sorted([price1, price2], reverse=True)
                        else:
                            entry_prices = sorted([price1, price2])
                except (ValueError, IndexError):
                    continue

        # 3. –ï—Å–ª–∏ –ù–ï —Ä—ã–Ω–æ—á–Ω—ã–π –∏ –Ω–µ –Ω–∞—à–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω - –∏—â–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Ü–µ–Ω—ã
        if not is_market and not entry_prices:
            entry_price_candidates = self.find_prices_by_context(text, self.patterns["entry"])

            if entry_price_candidates:
                entry_prices = entry_price_candidates

        logger.info(f"üîç Entry detection - is_market: {is_market}, entry_prices: {entry_prices}")
        return entry_prices, limit_prices, is_market

    def extract_take_profits(self, text: str, direction: str, entry_price: Optional[float]) -> List[float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç—ã"""
        if not text:
            return []

        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        tp_candidates = self.find_prices_by_context(text, self.patterns["take_profit"])

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –ª—é–±—ã–µ —Ü–µ–Ω—ã –ø–æ—Å–ª–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if not tp_candidates:
            lines = text.split('\n')
            in_tp_section = False

            for line in lines:
                line_lower = line.lower()

                # –í—Ö–æ–¥–∏–º –≤ —Å–µ–∫—Ü–∏—é —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–æ–≤
                if any(keyword in line_lower for keyword in self.patterns["take_profit"]):
                    in_tp_section = True

                # –ï—Å–ª–∏ –≤ —Å–µ–∫—Ü–∏–∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–æ–≤
                if in_tp_section:
                    prices = self.extract_prices_from_line(line, filter_percents=True)
                    if prices:
                        tp_candidates.extend(prices)

                    # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Å–µ–∫—Ü–∏–∏, –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –¥—Ä—É–≥—É—é –∫–ª—é—á–µ–≤—É—é —Å–µ–∫—Ü–∏—é
                    if any(keyword in line_lower for keyword in self.patterns["stop_loss"] + self.patterns["entry"]):
                        in_tp_section = False

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å —Ü–µ–Ω–∞ –≤—Ö–æ–¥–∞
        filtered_tps = []
        if direction == "LONG" and entry_price is not None:
            filtered_tps = [tp for tp in tp_candidates if tp > entry_price]
        elif direction == "SHORT" and entry_price is not None:
            filtered_tps = [tp for tp in tp_candidates if tp < entry_price]
        else:
            filtered_tps = tp_candidates

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        seen = set()
        unique_tps = []
        for tp in filtered_tps:
            if tp not in seen:
                seen.add(tp)
                unique_tps.append(tp)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        if direction == "SHORT":
            unique_tps.sort(reverse=True)
        elif direction == "LONG":
            unique_tps.sort()

        return unique_tps

    def extract_stop_loss(self, text: str) -> Optional[float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–æ–ø-–ª–æ—Å—Å"""
        if not text:
            return None

        # –ò—â–µ–º –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        sl_candidates = self.find_prices_by_context(text, self.patterns["stop_loss"])

        if sl_candidates:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã
            for candidate in sl_candidates:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º
                percent_pattern = rf'{re.escape(str(candidate))}\s*%'
                if not re.search(percent_pattern, text):
                    return candidate

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
        for line in text.split('\n'):
            line_lower = line.lower()
            if any(keyword in line_lower for keyword in self.patterns["stop_loss"]):
                prices = self.extract_prices_from_line(line, filter_percents=True)
                if prices:
                    return prices[0]

        return None

    def parse_signal(self, text: str, source: str) -> TradeSignal:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        if not text or not isinstance(text, str):
            raise ValueError("–¢–µ–∫—Å—Ç —Å–∏–≥–Ω–∞–ª–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")

        if len(text) > 10000:
            logger.warning("–¢–µ–∫—Å—Ç —Å–∏–≥–Ω–∞–ª–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –æ–±—Ä–µ–∑–∞–µ–º –¥–æ 10000 —Å–∏–º–≤–æ–ª–æ–≤")
            text = text[:10000]

        logger.info(f"üîç Parsing signal from: {source}")

        try:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
            normalized_text = self.normalize_text(text)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
            detected_source = self.detect_source(normalized_text, source)
            logger.info(f"üîç Detected source: {detected_source}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            symbol = self.extract_symbol(normalized_text)
            direction = self.extract_direction(normalized_text)
            leverage = self.extract_leverage(normalized_text)
            margin = self.extract_margin(normalized_text)

            logger.info(f"üîç Symbol: {symbol}")
            logger.info(f"üîç Direction: {direction}")
            logger.info(f"üîç Leverage: {leverage}")
            if margin:
                logger.info(f"üîç Margin: {margin}%")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ö–æ–¥–µ
            entry_prices, limit_prices, is_market = self.extract_entry_info(normalized_text, detected_source)

            if is_market:
                logger.info("üîç Market order detected")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é —Ü–µ–Ω—É –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            base_price = None
            if entry_prices:
                base_price = entry_prices[0]
            elif limit_prices:
                base_price = limit_prices[0]

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç—ã
            take_profits = self.extract_take_profits(normalized_text, direction, base_price)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–æ–ø-–ª–æ—Å—Å
            stop_loss = self.extract_stop_loss(normalized_text)

            logger.info(f"üîç Entry prices: {entry_prices}")
            logger.info(f"üîç Limit prices: {limit_prices}")
            logger.info(f"üîç Take profits: {take_profits}")
            logger.info(f"üîç Stop loss: {stop_loss}")

            return TradeSignal(
                symbol=symbol,
                direction=direction,
                entry_prices=entry_prices,
                limit_prices=limit_prices,
                take_profits=take_profits,
                stop_loss=stop_loss,
                leverage=leverage,
                margin=margin,
                source=detected_source,
                timestamp=time.time(),
                is_market=is_market
            )
        except Exception as e:
            logger.error(f"‚ùå Error parsing signal: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª —Å –æ—à–∏–±–∫–æ–π
            return TradeSignal(
                symbol="ERROR",
                direction="UNKNOWN",
                entry_prices=[],
                limit_prices=[],
                take_profits=[],
                stop_loss=None,
                leverage=1,
                margin=None,
                source=source,
                timestamp=time.time(),
                is_market=False
            )

    def is_preliminary_announcement(self, text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ–º"""
        if not text:
            return False

        text_lower = text.lower()

        preliminary_keywords = [
            '–≥–æ—Ç–æ–≤—å—Å—è', '–ø—Ä–∏–≥–æ—Ç–æ–≤—å', '—Å–∫–æ—Ä–æ', '–±—É–¥–µ—Ç', '—Å–ª–µ–¥–∏',
            '–≤–Ω–∏–º–∞–Ω–∏–µ', '–æ–±—ä—è–≤–ª—è—é', '–∞–Ω–æ–Ω—Å', '–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ',
            '–∂–¥—É', '–æ–∂–∏–¥–∞–π', '—Å–ª–µ–¥—É—é—â', '–≥–æ—Ç–æ–≤—å—Ç–µ—Å—å', '–≤—Å–∫–æ—Ä–µ',
            '–Ω–∞ –ø–æ–¥—Ö–æ–¥–µ', '–≥–æ—Ç–æ–≤—å—Ç–µ', '—Å–ª–µ–¥–∏—Ç–µ', '—Å–∫–æ—Ä–æ –≤—ã–ª–æ–∂—É',
            '–æ–∂–∏–¥–∞–π—Ç–µ', '–≤–Ω–∏–º–∞–Ω–∏–µ!', '–≤—Å–∫–æ—Ä–µ –±—É–¥–µ—Ç'
        ]

        has_preliminary = any(keyword in text_lower for keyword in preliminary_keywords)

        if has_preliminary:
            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            trading_data_count = 0

            if re.search(r'\d+[.,]\d+', text_lower):
                trading_data_count += 1

            if any(keyword in text_lower for keyword in self.patterns["entry"]):
                trading_data_count += 1

            if any(keyword in text_lower for keyword in self.patterns["take_profit"]):
                trading_data_count += 1

            if any(keyword in text_lower for keyword in self.patterns["stop_loss"]):
                trading_data_count += 1

            if trading_data_count < 2:
                return True

        return False


# –ì–õ–û–ë–ê–õ–¨–ù–´–ô –≠–ö–ó–ï–ú–ü–õ–Ø–†
universal_parser = UniversalSignalParser()

# –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
advanced_parser = universal_parser
